{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.nus.edu.sg/images/default-source/base/logo.png' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Machine Learning in Python</h1><h2>Lab 5b - Hierarchical Clustering </h2><h3></h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "You are working in a bank and your job is to analyze your customer information (e.g. age, annual salary and etc.) to find some patterns. This will help your sales team to target the right customers effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.preprocessing import StandardScaler, normalize \n",
    "from sklearn.metrics import silhouette_score \n",
    "import scipy.cluster.hierarchy as shc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Scaled the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dat = pd.read_csv('bank.csv')\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dat.loc[dat.sample(200, random_state = 0).index,['age', 'balance']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View number of items and data type of each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into numpy arrays\n",
    "X =df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the above two attributes are at very different ranges. Hierarchical Clustering is very sensitive on the ranges of attributes. Thus, before feed the data into the model, we need to scale the data first. In this example, we will be using Z-score transformation to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data so that all the features/attributes become comparable \n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_scaled[:,0], X_scaled[:,1])\n",
    "plt.xlabel('age_scaled')\n",
    "plt.ylabel('balance_scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distance Matrix and Dendorgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Generate Distance Matrix\n",
    "Here we will use `cdist` from `scipy` to generate the full distance matrix. It is just a line of code, you can have the full distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full distance matrix \n",
    "from scipy.spatial.distance import cdist\n",
    "print(cdist(X_scaled, X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdist(X_scaled, X_scaled).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Look for pairs of samples (i.e. clusters) with the lowest dissimilarity\n",
    "We use `linkage` function from `scipy.cluster.hierarchy` package to find the clusters with the lowest dissimilarity and merge them accordingly. You can choose different linkage methods, e.g. single, complete, average, ward and etc. Ward is the default method and it picks the two clusters to merge such that the variance within all clusters increases the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "help(shc.linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical/agglomerative clustering\n",
    "Z = shc.linkage(X_scaled, method ='ward') \n",
    "Z # A condensed distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above condensed distance matrix (`Z`) listed the two cluster (with the minimum distance) we are merging and their corresponding distance. It is impossible to read through this long list, thus we will be Dendrograms to visualize this hierarchical clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Generate Dendrograms.\n",
    "Use the `dendrogram` function from `scipy.cluster.hierarchy` package and feed in the condensed distance matrix `Z` generated in Step 2, we can easily generate the below Dendrogram for us to visualize the linkage relationship between different points/clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the hierarchical clustering through Dendrograms\n",
    "plt.figure(figsize =(12, 12)) \n",
    "plt.title('Visualising the Hierarchical Clustering') \n",
    "Dendrogram = shc.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, it seems three clusters may be a good choice to start from.\n",
    "\n",
    "In case you're wondering about where the colors come from, you might want to have a look at the color_threshold argument of dendrogram(), which as not specified automagically picked a distance cut-off value of 70 % of the final merge and then colored the first clusters below that in individual colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Agglomerative Clusting model with number of clusters set as 3\n",
    "ac3 = AgglomerativeClustering(n_clusters = 3)\n",
    "ac3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and predict the clusters\n",
    "ac3.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Three Clusters\n",
    "plt.figure(figsize =(6, 6)) \n",
    "plt.scatter(X_scaled[:,0], X_scaled[:,1], \n",
    "            c = ac3.fit_predict(X_scaled), cmap ='rainbow') \n",
    "plt.xlabel('age_scaled')\n",
    "plt.ylabel('balance_scaled')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters\n",
    "ac3.n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label of each data point/sample\n",
    "ac3.labels_ \n",
    "# same as 'ac3.fit_predict(X_scaled)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Sihouette Score to evaluate the model. This can be done in one line of code by using `silhouette_score` function from `sklearn.metrics`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Silhouette Score\n",
    "from sklearn.metrics import silhouette_score \n",
    "silhouette_score(X_scaled, ac3.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good starting point. In the below section, we will try a range of n_clusters values (i.e. the numer of clusters) and find the best model with the highest silhouette score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Improve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to evaluate the Silhouette Scores for different K, i.e. n_clusters (ranging from 2 to 11)\n",
    "k_range = range(2,11)\n",
    "silhouette_scores =[]\n",
    "\n",
    "for i in k_range:\n",
    "    ac_i = AgglomerativeClustering(n_clusters = i,linkage='ward')\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, ac_i.fit_predict(X_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Silhouette Scores using a bar graph to compare the results \n",
    "plt.bar(k_range, silhouette_scores) \n",
    "plt.xlabel('Number of clusters', fontsize = 20) \n",
    "plt.ylabel('Silouette Score', fontsize = 20)\n",
    "plt.axis([1, 11, 0.3, 0.55])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see `n_clusters = 5` (i.e. Five Clusters) is having the highest Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model with n_clusters = 5\n",
    "ac5 = AgglomerativeClustering(n_clusters = 5)\n",
    "ac5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac5.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.figure(figsize =(6, 6)) \n",
    "plt.scatter(X_scaled[:,0], X_scaled[:,1], \n",
    "            c = ac5.fit_predict(X_scaled), cmap ='rainbow')\n",
    "plt.xlabel('age_scaled')\n",
    "plt.ylabel('balance_scaled')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(X_scaled, ac5.fit_predict(X_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the number of clusters from Three to Five, We manage to improve the silhouette score from 0.38 to 0.40. Moreover, from the above graph we can easily identify two outlier clusters: \n",
    "* customers with super high balance <font color='green'>(Green)</font> \n",
    "* super senior customers <font color=FFAE33>(Yellow)</font> \n",
    "\n",
    "This will help us to understand and prepare the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
